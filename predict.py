from cog import BasePredictor, Input, Path
from diffusers import StableDiffusionPipeline
import torch
import sys

# –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –∏–∑ default_prompts.py
DEFAULT_POSITIVE_PROMPTS = [
    "Clean lines",
    "Perfect hands",
    "Detailed realistic hair",
    "Detailed realistic face",
    "Detailed realistic body",
    "Detailed realistic hands",
    "Detailed realistic feet",
    "Detailed realistic legs",
    "Detailed realistic boobs",
    "Detailed realistic eyes",
    "Realistic lighting",
    "beautiful iris",
    "symmetrical face",
    "Cinematic lighting",
    "Hi-Res",
    "Best quality",
    "Semi-Realistic",
    "Lazypos",
    "Photorealistic",
    "Realistic Tint",
    "Highly aesthetic",
    "Depth of field",
    "High-Res",
    "Newst-ai"
]

DEFAULT_NEGATIVE_PROMPTS = [
    'poorly_detailed',
    'worst_quality',
    'bad_quality',
    'extra fingers',
    'missing fingers',
    'lowres',
    'low resolution bad anatomy',
    'extra digits',
    'jpeg artifacts',
    'signature',
    'watermark',
    'username',
    'conjoined',
    'deformed fingers',
    'short legs',
    'body diproportion',
    'bad ai-generated',
    'text',
    'halo',
    'multiple views',
    'displeasing',
    'messy composition',
    'clones'
]


def get_default_positive_prompts() -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏"""
    return ", ".join(DEFAULT_POSITIVE_PROMPTS)


def get_default_negative_prompts() -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏"""
    return ", ".join(DEFAULT_NEGATIVE_PROMPTS)


def combine_prompts(user_prompt: str, default_positive: str) -> str:
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏.
    –ü–æ—Ä—è–¥–æ–∫: –ø—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ‚Üí –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
    """
    if not user_prompt:
        return default_positive

    if not default_positive:
        return user_prompt

    # –ü—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–¥–µ—Ç –ø–µ—Ä–≤—ã–º, –∑–∞—Ç–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
    return f"{user_prompt}, {default_positive}"


class Predictor(BasePredictor):
    def setup(self):
        print(f"üî¥ PYTHON VERSION: {sys.version}")
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è Replicate (GPU)"""
        self.pipe = StableDiffusionPipeline.from_single_file(
            "./weights/oneObsession_v18.safetensors",
            torch_dtype=torch.float16,  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º float16 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            load_safety_checker=False   # –û—Ç–∫–ª—é—á–∞–µ–º –ª–∏—à–Ω—é—é –∑–∞–≥—Ä—É–∑–∫—É
        )
        self.pipe.to("cuda")            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É

    def predict(
        self,
        prompt: str = Input(
            description="Input prompt",
            default="masterpiece, best quality, girl"
        ),
        negative_prompt: str = Input(
            description="Negative prompt",
            default=None
        ),
        width: int = Input(description="Width", default=832),
        height: int = Input(description="Height", default=1216),
        num_inference_steps: int = Input(description="Steps", default=30),
        guidance_scale: float = Input(description="CFG Scale", default=7.0),
        seed: int = Input(description="Seed", default=None),
    ) -> Path:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤.
        –ü–æ—Ä—è–¥–æ–∫: –ø—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ‚Üí –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        """
        # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        default_positive = get_default_positive_prompts()
        default_negative = get_default_negative_prompts()

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
        # –ü–æ—Ä—è–¥–æ–∫: –ø—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ‚Üí –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        if prompt:
            final_prompt = combine_prompts(prompt, default_positive)
        else:
            final_prompt = default_positive

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        if negative_prompt:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç,
            # –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º
            final_negative_prompt = f"{negative_prompt}, {default_negative}"
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π
            final_negative_prompt = default_negative

        print(f"[PROMPT] –ò—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {prompt[:100]}...")
        print(f"[PROMPT] –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {final_prompt[:150]}...")
        print(
            f"[PROMPT] –§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç: "
            f"{final_negative_prompt[:150]}..."
        )

        if seed is None:
            seed = int.from_bytes(torch.os.urandom(2), "big")
        print(f"Generating with seed: {seed}")

        generator = torch.Generator("cuda").manual_seed(seed)

        output = self.pipe(
            prompt=final_prompt,
            negative_prompt=final_negative_prompt,
            width=width,
            height=height,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            generator=generator
        )

        out_path = Path("/tmp/output.png")
        output.images[0].save(out_path)
        return out_path
